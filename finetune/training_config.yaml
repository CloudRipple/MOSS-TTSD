per_device_train_batch_size: 1
gradient_accumulation_steps: 1
num_train_epochs: 50
learning_rate: 1e-4
bf16: true
logging_steps: 10
save_steps: 10
save_total_limit: 100
dataloader_num_workers: 1
warmup_ratio: 0.1
lr_scheduler_type: "cosine"
gradient_checkpointing: true